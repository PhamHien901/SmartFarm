import gspread
import pandas as pd
import numpy as np
import json
import os
from oauth2client.service_account import ServiceAccountCredentials
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import GRU, Dense
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.losses import MeanSquaredError
from datetime import datetime, timedelta

# ======= K·∫æT N·ªêI GOOGLE SHEETS =========
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
creds = ServiceAccountCredentials.from_json_keyfile_name(
    "C:/Users/hieuv/PycharmProjects/GRU/focal-grin-455408-m0-c0013e6015d9.json", scope)
client = gspread.authorize(creds)

# ƒê·ªçc d·ªØ li·ªáu t·ª´ sheet
sheet_url = "https://docs.google.com/spreadsheets/d/19qBwHPrIes6PeGAyIzMORPVB-7utQpaZG7RHrdRfoNI/edit#gid=0"
sheet = client.open_by_url(sheet_url)
worksheet = sheet.worksheet("DATA")
data = pd.DataFrame(worksheet.get_all_records())

# ======= X·ª¨ L√ù C·ªòT TH·ªúI GIAN =========
data['timestamp'] = pd.to_datetime(data['NG√ÄY'] + ' ' + data['GI·ªú'], format='%d/%m/%Y %H:%M:%S')
data = data.sort_values('timestamp')

# ƒê·ªïi t√™n c·ªôt
data.rename(columns={
    'temperature': 'temp',
    'humidity': 'humid',
    'soil_moisture': 'soil',
    'wind': 'wind',
    'rain': 'rain'
}, inplace=True)

# ======= ƒê·ªåC TIMESTAMP TR∆Ø·ªöC ƒê√ì (N·∫æU C√ì) =========
saved_timestamp = None
if os.path.exists("last_timestamp.json"):
    with open("last_timestamp.json", "r") as f:
        saved_timestamp = pd.to_datetime(json.load(f)["last_timestamp"])

latest_timestamp = data['timestamp'].iloc[-1]

# ======= CHU·∫®N H√ìA D·ªÆ LI·ªÜU =========
features = ['temp', 'humid', 'soil', 'wind', 'rain']
dataset = data[features].copy()

scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(dataset)

# ======= LU√îN LU√îN D·ª∞ B√ÅO V√Ä L∆ØU JSON =========
model_path = "gru_weather_model.h5"
window_size = 6

# Load model n·∫øu ch∆∞a load trong kh·ªëi else
if not os.path.exists(model_path):
    print("‚ö†Ô∏è Ch∆∞a c√≥ m√¥ h√¨nh, s·∫Ω t·∫°o m·ªõi.")
    model = Sequential()
    model.add(GRU(units=64, return_sequences=False, input_shape=(window_size, len(features))))
    model.add(Dense(5))
    model.compile(optimizer='adam', loss=MeanSquaredError())
    model.save(model_path)
else:
    model = load_model(model_path, compile=False)
    model.compile(optimizer='adam', loss=MeanSquaredError())

# ======= D·ª∞ B√ÅO 24 KHUNG GI·ªú TI·∫æP THEO (24H) =========
n_steps = 25  # C·∫≠p nh·∫≠t s·ªë b∆∞·ªõc l√™n 24 ƒë·ªÉ d·ª± b√°o cho 24h
forecast = []

current_seq = scaled_data[-window_size:].copy()

for step in range(n_steps):
    x_input = current_seq.reshape(1, window_size, len(features))
    y_pred = model.predict(x_input)
    forecast.append(y_pred[0])
    current_seq = np.vstack([current_seq[1:], y_pred])

forecast_original = scaler.inverse_transform(np.array(forecast))
forecast_df = pd.DataFrame(forecast_original, columns=features)

forecast_df = forecast_df.clip(lower=0)
forecast_df = forecast_df.round(2)

# Th√™m c·ªôt gi·ªù: m·ªëc hi·ªán t·∫°i + 1h m·ªói b∆∞·ªõc
base_time_tomorrow = (datetime.now() + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)

# C·∫≠p nh·∫≠t th·ªùi gian cho t·ª´ng khung gi·ªù v√† g·∫Øn v·ªõi ng√†y mai
forecast_df.insert(0, "time", [(base_time_tomorrow + timedelta(hours=i)).strftime("%d/%m/%Y %H:%M") for i in range(n_steps)])

# L∆∞u ra JSON
forecast_df.to_json("C:/Users/hieuv/PycharmProjects/GRU/latest_prediction.json", orient="records", indent=2)
print("üì§ D·ª± b√°o 24h t·ªõi ƒë√£ l∆∞u v√†o latest_prediction.json")

# ======= ƒê·∫®Y D·ªÆ LI·ªÜU L√äN FIREBASE REALTIME DATABASE =========
import firebase_admin
from firebase_admin import credentials, db

if not firebase_admin._apps:
    cred = credentials.Certificate("C:/Users/hieuv/PycharmProjects/GRU/smart-farm-6e42d-firebase-adminsdk-fbsvc-9f6b7c2379.json")
    firebase_admin.initialize_app(cred, {
        'databaseURL': 'https://smart-farm-6e42d-default-rtdb.firebaseio.com/'
    })

forecast_data = forecast_df.to_dict(orient="records")

# Ch·ªâ ƒë·∫©y d·ªØ li·ªáu d·ª± b√°o ng√†y mai l√™n Firebase d∆∞·ªõi m·ª•c 'forecast/tomorrow'
ref = db.reference("forecast/tomorrow")
ref.set(forecast_data)

print("üî• ƒê√£ ƒë·∫©y d·ª± b√°o 24h t·ªõi l√™n Firebase th√†nh c√¥ng!")


# ======= HU·∫§N LUY·ªÜN N·∫æU C√ì D·ªÆ LI·ªÜU M·ªöI =========
if saved_timestamp is not None and latest_timestamp <= saved_timestamp:
    print("üü° Kh√¥ng c√≥ d·ªØ li·ªáu m·ªõi. B·ªè qua hu·∫•n luy·ªán.")
else:
    print("üü¢ C√≥ d·ªØ li·ªáu m·ªõi. Ti·∫øn h√†nh hu·∫•n luy·ªán m√¥ h√¨nh...")

    X, y = [], []
    for i in range(len(scaled_data) - window_size):
        X.append(scaled_data[i:i + window_size])
        y.append(scaled_data[i + window_size])
    X = np.array(X)
    y = np.array(y)

    if not 'model' in locals():
        model = load_model(model_path, compile=False)
        model.compile(optimizer='adam', loss=MeanSquaredError())

    early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)
    model.fit(X, y, epochs=100, batch_size=16, callbacks=[early_stop])
    model.save(model_path)

    with open("last_timestamp.json", "w") as f:
        json.dump({"last_timestamp": str(latest_timestamp)}, f)

    print("‚úÖ ƒê√£ hu·∫•n luy·ªán m√¥ h√¨nh v√† c·∫≠p nh·∫≠t timestamp.")
